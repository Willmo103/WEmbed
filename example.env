# Example environment variables

# APP_STORAGE is the data storage path used by the application for storing
# the local sqlite database, the markdown files, and other application data
APP_STORAGE = '/your/app/storage/path'

# OLLAMA_HOST is the host URL for the Ollama API by default Ollama uses
# http://localhost:11434, you can change it to your Ollama server URL
# if desired.
OLLAMA_HOST = 'http://localhost:11434'

# the HOST and USER are the hostname for the Host machine the service is running on
# and the Username of the user running the application. This is recorded for
# determining the various versions where files exist on multiple machines
# When syncing to the future API or a shared database.
HOST = 'wembed_host'
USER = 'wembed_user'

# MAX_TOKENS - Maximum number of embedding tokens.
MAX_TOKENS = 2048

# EMBEDDING_LENGTH - Length of the embedding vector.
EMBEDDING_LENGTH = 768

# Both MAX_TOKENS and EMBEDDING_LENGTH should be set according to the model being used.
# If using Ollama you may view the tokens via running
# `ollama model show <model_name> -v`
# You should see somehing like:
# ```shell
#    Metadata
#        general.architecture                       nomic-bert
#        general.file_type                          1
#        general.parameter_count                    1.3672704e+08
#        nomic-bert.attention.causal                false
#        nomic-bert.attention.head_count            12
#        nomic-bert.attention.layer_norm_epsilon    1e-12
#        nomic-bert.block_count                     12
#        nomic-bert.context_length                  **2048** <- This is the maximum context length, you should not exceed this
#        nomic-bert.embedding_length                **768** <- This is the embedding length, you should not exceed this
#        nomic-bert.feed_forward_length             3072
#        nomic-bert.pooling_type                    1
#```

# Hugging Face model ID for the embedding model (For use with Docling's HybridChunker to allow for chunk contextualization)
EMBED_MODEL_HF_ID = 'nomic-ai/nomic-embed-text-v1.5'

# The name the llm library needs for the chosen embedding model
EMBED_MODEL_NAME = 'nomic-embed-text'

# SQLALCHEMY_DATABASE_URI is the database connection string for the database. Currently only PostgreSQL and SQLite are natively supported.
SQLALCHEMY_DATABASE_URI = 'postgresql+psycopg2://wembed_db_admin:wembed_db_password@localhost/wembed'

# __future__: The CHROMA_PATH and QDRANT_PATH will be implemented in future versions.
# These paths will be used to store embeddings using the client API each library exposes for
# on-disk implementations.
# CHROMA_PATH = ''
# CHROMA_HTTP_URL = ''
# QDRANT_PATH = ''
# QDRANT_HTTP_URL = ''
